{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aljunalei/rag-thesis-cloud/blob/main/LiPAD_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKzR2LeRtJ6G",
        "outputId": "7c482802-4a29-400f-91d5-58e968eb2a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Aligning environment dependencies...\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hğŸ“š Installing RAG libraries...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Setup Complete. Ignore any 'pip' red error text above if 'Successfully installed' appears.\n"
          ]
        }
      ],
      "source": [
        "# --- STEP 1: FORCE ALIGN DEPENDENCIES ---\n",
        "print(\"ğŸ”§ Aligning environment dependencies...\")\n",
        "!pip install -q \\\n",
        "    requests==2.32.4 \\\n",
        "    opentelemetry-api==1.37.0 \\\n",
        "    opentelemetry-sdk==1.37.0 \\\n",
        "    opentelemetry-proto==1.37.0 \\\n",
        "    opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
        "    opentelemetry-exporter-otlp-proto-http==1.37.0 \\\n",
        "    opentelemetry-exporter-otlp-proto-grpc==1.37.0 \\\n",
        "    google-adk==1.17.0\n",
        "\n",
        "# --- STEP 2: INSTALL YOUR RAG STACK ---\n",
        "print(\"ğŸ“š Installing RAG libraries...\")\n",
        "!pip install -q \\\n",
        "    langchain langchain-core langchain-community langchain-huggingface \\\n",
        "    pypdf pymupdf sentence-transformers faiss-cpu chromadb \\\n",
        "    python-dotenv fastapi uvicorn[standard] pydantic[email] python-multipart \\\n",
        "    pyngrok bitsandbytes accelerate\n",
        "\n",
        "print(\"âœ… Setup Complete. Ignore any 'pip' red error text above if 'Successfully installed' appears.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpDHu7B4cHWS",
        "outputId": "050576b8-f8b0-46d7-a129-74726734f4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/10.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/10.2 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m9.9/10.2 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m241.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgQIa9jqcDki"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clls6E1jGE44",
        "outputId": "64d8de0e-c84a-4d5f-a716-f2fc7a7aa041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader, TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "\n",
        "st.set_page_config(page_title=\"Thesis RAG\", layout=\"wide\")\n",
        "DB_DIR = \"./chroma_db\"\n",
        "DATA_DIR = \"./data\"\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "\n",
        "    * {\n",
        "        font-family: 'Inter', -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n",
        "    }\n",
        "\n",
        "    .main {\n",
        "        background-color: #000000;\n",
        "        padding: 0;\n",
        "    }\n",
        "\n",
        "    .stApp {\n",
        "        background-color: #000000;\n",
        "    }\n",
        "\n",
        "    .block-container {\n",
        "        padding-top: 0;\n",
        "        padding-bottom: 120px;\n",
        "        max-width: 680px;\n",
        "    }\n",
        "\n",
        "    [data-testid=\"stSidebar\"] {\n",
        "        background-color: #000000;\n",
        "        border-right: 1px solid #2f3336;\n",
        "    }\n",
        "\n",
        "    [data-testid=\"stSidebar\"] * {\n",
        "        color: #e7e9ea !important;\n",
        "    }\n",
        "\n",
        "    .header-bar {\n",
        "        position: sticky;\n",
        "        top: 0;\n",
        "        z-index: 1000;\n",
        "        background-color: rgba(0, 0, 0, 0.65);\n",
        "        backdrop-filter: blur(12px);\n",
        "        border-bottom: 1px solid #2f3336;\n",
        "        padding: 12px 16px;\n",
        "        margin-bottom: 0;\n",
        "    }\n",
        "\n",
        "    .header-title {\n",
        "        font-size: 20px;\n",
        "        font-weight: 700;\n",
        "        color: #e7e9ea;\n",
        "        margin: 0;\n",
        "        letter-spacing: -0.3px;\n",
        "    }\n",
        "\n",
        "    .tweet-card {\n",
        "        background-color: #000000;\n",
        "        border-bottom: 1px solid #2f3336;\n",
        "        padding: 12px 16px;\n",
        "        transition: background-color 0.2s ease;\n",
        "        position: relative;\n",
        "    }\n",
        "\n",
        "    .tweet-card:hover {\n",
        "        background-color: rgba(255, 255, 255, 0.03);\n",
        "    }\n",
        "\n",
        "    .tweet-main {\n",
        "        display: flex;\n",
        "        gap: 12px;\n",
        "    }\n",
        "\n",
        "    .tweet-avatar {\n",
        "        width: 48px;\n",
        "        height: 48px;\n",
        "        border-radius: 50%;\n",
        "        flex-shrink: 0;\n",
        "        display: flex;\n",
        "        align-items: center;\n",
        "        justify-content: center;\n",
        "        font-weight: 700;\n",
        "        font-size: 20px;\n",
        "        background: linear-gradient(135deg, #1d9bf0, #0c7abf);\n",
        "        color: #ffffff;\n",
        "    }\n",
        "\n",
        "    .avatar-user {\n",
        "        background: linear-gradient(135deg, #1d9bf0, #0c7abf);\n",
        "    }\n",
        "\n",
        "    .avatar-assistant {\n",
        "        background: linear-gradient(135deg, #7856ff, #5b3fd1);\n",
        "    }\n",
        "\n",
        "    .tweet-body {\n",
        "        flex: 1;\n",
        "        min-width: 0;\n",
        "    }\n",
        "\n",
        "    .tweet-header {\n",
        "        display: flex;\n",
        "        align-items: center;\n",
        "        gap: 4px;\n",
        "        margin-bottom: 4px;\n",
        "    }\n",
        "\n",
        "    .tweet-name {\n",
        "        font-weight: 700;\n",
        "        font-size: 15px;\n",
        "        color: #e7e9ea;\n",
        "        line-height: 20px;\n",
        "    }\n",
        "\n",
        "    .tweet-handle {\n",
        "        font-weight: 400;\n",
        "        font-size: 15px;\n",
        "        color: #71767b;\n",
        "        line-height: 20px;\n",
        "    }\n",
        "\n",
        "    .tweet-content {\n",
        "        font-size: 15px;\n",
        "        line-height: 20px;\n",
        "        color: #e7e9ea;\n",
        "        word-wrap: break-word;\n",
        "        white-space: pre-wrap;\n",
        "        margin-top: 2px;\n",
        "    }\n",
        "\n",
        "    .reply-indicator {\n",
        "        position: absolute;\n",
        "        left: 39px;\n",
        "        top: 68px;\n",
        "        bottom: -12px;\n",
        "        width: 2px;\n",
        "        background-color: #2f3336;\n",
        "    }\n",
        "\n",
        "    .reply-card {\n",
        "        border-left: 2px solid #2f3336;\n",
        "        margin-left: 39px;\n",
        "        padding-left: 28px;\n",
        "    }\n",
        "\n",
        "    .input-box {\n",
        "        position: fixed;\n",
        "        bottom: 0;\n",
        "        left: 0;\n",
        "        right: 0;\n",
        "        background-color: rgba(0, 0, 0, 0.65);\n",
        "        backdrop-filter: blur(12px);\n",
        "        border-top: 1px solid #2f3336;\n",
        "        padding: 12px 16px;\n",
        "        z-index: 1000;\n",
        "    }\n",
        "\n",
        "    .stChatInput {\n",
        "        max-width: 680px;\n",
        "        margin: 0 auto;\n",
        "    }\n",
        "\n",
        "    .stChatInput > div {\n",
        "        border-radius: 20px !important;\n",
        "        border: 1px solid #2f3336 !important;\n",
        "        background-color: #000000 !important;\n",
        "    }\n",
        "\n",
        "    .stChatInput input {\n",
        "        color: #e7e9ea !important;\n",
        "        font-size: 15px !important;\n",
        "        background-color: transparent !important;\n",
        "    }\n",
        "\n",
        "    .stChatInput input::placeholder {\n",
        "        color: #71767b !important;\n",
        "    }\n",
        "\n",
        "    h1, h2, h3, h4, h5, h6, p, span, div, label {\n",
        "        color: #e7e9ea !important;\n",
        "    }\n",
        "\n",
        "    .stButton button {\n",
        "        background-color: #1d9bf0;\n",
        "        color: #ffffff;\n",
        "        border-radius: 20px;\n",
        "        border: none;\n",
        "        font-weight: 700;\n",
        "        padding: 8px 16px;\n",
        "        transition: background-color 0.2s ease;\n",
        "        font-size: 15px;\n",
        "    }\n",
        "\n",
        "    .stButton button:hover {\n",
        "        background-color: #1a8cd8;\n",
        "    }\n",
        "\n",
        "    .stTextInput input {\n",
        "        background-color: #000000;\n",
        "        color: #e7e9ea;\n",
        "        border: 1px solid #2f3336;\n",
        "        border-radius: 4px;\n",
        "    }\n",
        "\n",
        "    .stSpinner > div {\n",
        "        border-top-color: #1d9bf0 !important;\n",
        "    }\n",
        "\n",
        "    .stSuccess {\n",
        "        background-color: rgba(0, 186, 124, 0.1);\n",
        "        color: #00ba7c;\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "\n",
        "    .stInfo {\n",
        "        background-color: rgba(29, 155, 240, 0.1);\n",
        "        color: #1d9bf0;\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "\n",
        "    .stError {\n",
        "        background-color: rgba(249, 24, 128, 0.1);\n",
        "        color: #f91880;\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "\n",
        "    [data-testid=\"stChatInput\"] {\n",
        "        background-color: transparent;\n",
        "    }\n",
        "\n",
        "    .thinking-indicator {\n",
        "        display: flex;\n",
        "        align-items: center;\n",
        "        gap: 8px;\n",
        "        color: #71767b;\n",
        "        font-size: 14px;\n",
        "        padding: 12px 16px;\n",
        "    }\n",
        "\n",
        "    .dot-pulse {\n",
        "        display: flex;\n",
        "        gap: 4px;\n",
        "    }\n",
        "\n",
        "    .dot-pulse span {\n",
        "        width: 8px;\n",
        "        height: 8px;\n",
        "        border-radius: 50%;\n",
        "        background-color: #1d9bf0;\n",
        "        animation: pulse 1.4s infinite ease-in-out;\n",
        "    }\n",
        "\n",
        "    .dot-pulse span:nth-child(1) {\n",
        "        animation-delay: -0.32s;\n",
        "    }\n",
        "\n",
        "    .dot-pulse span:nth-child(2) {\n",
        "        animation-delay: -0.16s;\n",
        "    }\n",
        "\n",
        "    @keyframes pulse {\n",
        "        0%, 80%, 100% {\n",
        "            opacity: 0.4;\n",
        "            transform: scale(0.8);\n",
        "        }\n",
        "        40% {\n",
        "            opacity: 1;\n",
        "            transform: scale(1);\n",
        "        }\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "@st.cache_resource\n",
        "def load_llm(hf_token):\n",
        "    model_id = \"unsloth/gemma-2-9b-it-bnb-4bit\"\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "            token=hf_token\n",
        "        )\n",
        "        pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.3,\n",
        "            return_full_text=False\n",
        "        )\n",
        "        return HuggingFacePipeline(pipeline=pipe)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Model Error: {e}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def setup_vector_db():\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    if not os.path.exists(DB_DIR) or not os.listdir(DB_DIR):\n",
        "        if not os.path.exists(DATA_DIR):\n",
        "            return None, \"âš ï¸ Error: 'data' folder not found. Please create it and upload files.\"\n",
        "        with st.spinner(\"Processing Documents...\"):\n",
        "            pdf_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
        "            pdf_docs = pdf_loader.load()\n",
        "            txt_loader = DirectoryLoader(DATA_DIR, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
        "            txt_docs = txt_loader.load()\n",
        "            documents = pdf_docs + txt_docs\n",
        "            if not documents:\n",
        "                return None, \"âš ï¸ No documents found in 'data' folder.\"\n",
        "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "            chunks = text_splitter.split_documents(documents)\n",
        "            vectordb = Chroma.from_documents(\n",
        "                documents=chunks,\n",
        "                embedding=embeddings,\n",
        "                persist_directory=DB_DIR\n",
        "            )\n",
        "            return vectordb, f\"âœ… Indexed {len(documents)} files ({len(chunks)} chunks).\"\n",
        "    else:\n",
        "        vectordb = Chroma(persist_directory=DB_DIR, embedding_function=embeddings)\n",
        "        return vectordb, \"âœ… Database Loaded.\"\n",
        "\n",
        "with st.sidebar:\n",
        "    st.title(\"âš™ï¸ Settings\")\n",
        "    st.markdown(\"---\")\n",
        "    if 'HF_TOKEN' not in st.session_state:\n",
        "        token = st.text_input(\"Hugging Face Token\", type=\"password\", placeholder=\"hf_...\")\n",
        "        if token:\n",
        "            st.session_state['HF_TOKEN'] = token\n",
        "            st.rerun()\n",
        "    else:\n",
        "        st.success(\"âœ“ Authenticated\")\n",
        "    st.info(\"ğŸ“¦ Model: Unsloth Gemma-2-9b\")\n",
        "    st.markdown(\"---\")\n",
        "    if st.button(\"ğŸ”„ Refresh Database\"):\n",
        "        if os.path.exists(DB_DIR):\n",
        "            shutil.rmtree(DB_DIR)\n",
        "        st.rerun()\n",
        "\n",
        "st.markdown('<div class=\"header-bar\"><div class=\"header-title\">ğŸ“˜ Thesis RAG</div></div>', unsafe_allow_html=True)\n",
        "\n",
        "if 'HF_TOKEN' in st.session_state:\n",
        "    vectordb, status = setup_vector_db()\n",
        "    if vectordb:\n",
        "        llm = load_llm(st.session_state['HF_TOKEN'])\n",
        "        if llm:\n",
        "            st.toast(status)\n",
        "            if \"messages\" not in st.session_state:\n",
        "                st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Hey! Ask me anything about your thesis or source code. I'm here to help! ğŸš€\"}]\n",
        "\n",
        "            for idx, msg in enumerate(st.session_state.messages):\n",
        "                is_last_user = msg[\"role\"] == \"user\" and idx < len(st.session_state.messages) - 1\n",
        "\n",
        "                if msg[\"role\"] == \"user\":\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"tweet-card\">\n",
        "                        <div class=\"tweet-main\">\n",
        "                            <div class=\"tweet-avatar avatar-user\">Y</div>\n",
        "                            <div class=\"tweet-body\">\n",
        "                                <div class=\"tweet-header\">\n",
        "                                    <span class=\"tweet-name\">You</span>\n",
        "                                    <span class=\"tweet-handle\">@user</span>\n",
        "                                </div>\n",
        "                                <div class=\"tweet-content\">{msg[\"content\"]}</div>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                        {f'<div class=\"reply-indicator\"></div>' if is_last_user else ''}\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "                else:\n",
        "                    is_reply = idx > 0 and st.session_state.messages[idx-1][\"role\"] == \"user\"\n",
        "                    card_class = \"tweet-card reply-card\" if is_reply else \"tweet-card\"\n",
        "\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"{card_class}\">\n",
        "                        <div class=\"tweet-main\">\n",
        "                            <div class=\"tweet-avatar avatar-assistant\">AI</div>\n",
        "                            <div class=\"tweet-body\">\n",
        "                                <div class=\"tweet-header\">\n",
        "                                    <span class=\"tweet-name\">Thesis Assistant</span>\n",
        "                                    <span class=\"tweet-handle\">@thesis_ai</span>\n",
        "                                </div>\n",
        "                                <div class=\"tweet-content\">{msg[\"content\"]}</div>\n",
        "                            </div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            if prompt := st.chat_input(\"What's on your mind?\"):\n",
        "                st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "                with st.spinner(\"\"):\n",
        "                    retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
        "                    docs = retriever.invoke(prompt)\n",
        "                    context_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "                    rag_prompt = f\"Context:\\n{context_text}\\n\\nQuestion: {prompt}\\n\\nAnswer:\"\n",
        "                    response = llm.invoke(rag_prompt)\n",
        "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "                st.rerun()\n",
        "    else:\n",
        "        st.error(status)\n",
        "else:\n",
        "    st.info(\"ğŸ‘ˆ Please enter your Hugging Face token in the sidebar to get started.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6AATIVRJmTW",
        "outputId": "1918bf96-3434-4df6-a436-986e1f6d21ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Ensuring Streamlit is installed...\n",
            "Paste Ngrok Token:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "ğŸ”ª Clearing old sessions...\n",
            "ğŸš€ Starting Streamlit...\n",
            "â³ Initializing (Waiting 8 seconds)...\n",
            "\n",
            "âœ… YOUR APP IS LIVE: https://styliform-ephraim-unsignified.ngrok-free.dev\n",
            "ğŸ“± Access it from anywhere using the URL above\n",
            "ğŸ”’ Connection is secure (HTTPS)\n",
            "\n",
            "ğŸ’¡ Keep this terminal running to maintain the tunnel\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "import signal\n",
        "\n",
        "# --- 1. FORCE INSTALL STREAMLIT ---\n",
        "print(\"ğŸ”§ Ensuring Streamlit is installed...\")\n",
        "subprocess.run([\"pip\", \"install\", \"-q\", \"streamlit\", \"pyngrok\"])\n",
        "\n",
        "# --- 2. AUTHENTICATE NGROK ---\n",
        "if not conf.get_default().auth_token:\n",
        "    print(\"Paste Ngrok Token:\")\n",
        "    conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "# --- 3. KILL OLD PROCESSES (AGGRESSIVE) ---\n",
        "print(\"ğŸ”ª Clearing old sessions...\")\n",
        "ngrok.kill()\n",
        "\n",
        "# Kill all streamlit processes\n",
        "os.system(\"pkill -9 streamlit\")\n",
        "os.system(\"pkill -9 -f 'streamlit run'\")\n",
        "\n",
        "# Kill any process using port 8501\n",
        "os.system(\"lsof -ti:8501 | xargs kill -9 2>/dev/null\")\n",
        "\n",
        "# Wait for cleanup\n",
        "time.sleep(2)\n",
        "\n",
        "# --- 4. START STREAMLIT ---\n",
        "print(\"ğŸš€ Starting Streamlit...\")\n",
        "log_file = open('streamlit_logs.txt', 'w')\n",
        "\n",
        "process = subprocess.Popen(\n",
        "    ['python', '-m', 'streamlit', 'run', 'app.py',\n",
        "     '--server.port', '8501',\n",
        "     '--server.address', '127.0.0.1',\n",
        "     '--server.headless', 'true',\n",
        "     '--browser.gatherUsageStats', 'false'],\n",
        "    stdout=log_file,\n",
        "    stderr=log_file\n",
        ")\n",
        "\n",
        "# --- 5. HEALTH CHECK ---\n",
        "print(\"â³ Initializing (Waiting 8 seconds)...\")\n",
        "time.sleep(8)\n",
        "\n",
        "if process.poll() is not None:\n",
        "    print(\"\\nâŒ ERROR: Streamlit crashed! Logs:\")\n",
        "    print(\"=\"*50)\n",
        "    with open('streamlit_logs.txt', 'r') as f:\n",
        "        print(f.read())\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    try:\n",
        "        public_url = ngrok.connect(addr=\"127.0.0.1:8501\", bind_tls=True).public_url\n",
        "        print(f\"\\nâœ… YOUR APP IS LIVE: {public_url}\")\n",
        "        print(f\"ğŸ“± Access it from anywhere using the URL above\")\n",
        "        print(f\"ğŸ”’ Connection is secure (HTTPS)\")\n",
        "        print(f\"\\nğŸ’¡ Keep this terminal running to maintain the tunnel\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ngrok Error: {e}\")\n",
        "        print(f\"ğŸ’¡ Try: 1) Check your ngrok token, 2) Restart ngrok service\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alQMeKjH5gi2",
        "outputId": "12e77843-bed3-42f9-d778-b67ee2257018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUVlnPvnS-XW"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}